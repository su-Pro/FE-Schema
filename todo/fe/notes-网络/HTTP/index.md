本文总结了我学习 HTTP 第一遍、第二遍的知识点，以自问自答形式作为面试复习脉络，梳理看似“杂乱” 的 HTTP（方便第二遍快速深入）。

- 如果您阅读本文相对吃力，可以参考我学习的途径进行系统的学习后再阅读本文。

- 如果您觉得对您有帮助，可以点赞支持一下（后续还有很多类似的整理，在重构中 🙃）

- 如果您非常期待其他的整理，可以先查阅我的[仓库](https://github.com/sup-fiveyear/Notes)（虽然现在还不是很成体系，但如果你也是校招党，可能会给你全面复习的思路 🙃）

**途径：图解 HTTP ➕[极客时间：透视 HTTP](https://time.geekbang.org/column/intro/100029001) + 三元大佬博客（太出名，地址就不贴了）**

**最后万分感谢神三元大佬教会我如何做笔记，如何整理知识点（虽然遥遥两地，他也不认识我 🙃）**

## 1. 你是如何理解 HTTP 的？特点有哪些？

### 超文本传输协议

> HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的**约定和规范**

HTTP 通常跑在 TCP/IP 协议栈之上,依靠 IP 协议实现寻址和路由、TCP 协议实现可靠数据传输、DNS 协议实现域名查找、SSL/TLS 协议实现安全通信。

此外,还有一些协议依赖于 HTTP,例如 WebSocket、HTTPDNS 等。这些协议相互交织,构成了一个协议网,而 HTTP 则处于中心地位。

### 特点

#### “可靠的传输协议”

因为 HTTP 协议是基于 TCP/IP 的,而 TCP 本身是一个“可靠”的传输协议,所以 HTTP 自然也就继承了这个特性,能够在请求方和应答方之间“可靠”地传输数据。

#### 应用层的协议

在 TCP/IP 诞生后的几十年里,虽然出现了许多的应用层协议,但它们都仅关注很小的应用领域,局限在很少的应用场景。例如 FTP 只能传输文件、SSH 只能远程登录等,在通用的数据传输方面“完全不能打”。

> HTTP 几乎可以传递一切东西（只要不太苛求性能）,满足各种需求,称得上是一个“万能”的协议。

#### 无状态

状态是指：客户端或者服务器里保存的一些数据或者标志,记录了通信过程中的一些变化信息。

> 形象地来说就是“没有记忆能力”。但不要忘了 “灵活可扩展”,虽然标准里没有规定“状态”,但完全能够在协议的框架里给它“打个补丁”,增加这个特性(cookie)。

#### 请求-应答

请求 - 应答模式也明确了 HTTP 协议里通信双方的定位,永远是请求方先发起连接和请求,是主动的.而应答方只有在收到请求后才能答复,是被动的,如果没有请求时不会有任何动作。

> 当然,请求方和应答方的角色也不是绝对的,在浏览器 - 服务器的场景里,通常服务器都是应答方,但如果将它作为代理服务器连接后端服务器,那么它就可能同时扮演请求方（对下）和应答方（对上）的角色。

#### 灵活可拓展

HTTP 报文里的各个组成部分都没有做严格的语法语义限制,可以由开发者任意定制。

## 2. 你知道 HTTP 都有哪些版本吗？

### 蒂姆·伯纳斯-李 万维网

1989 年,任职于欧洲核子研究中心(CERN)的蒂姆·伯纳斯 - 李 创造了万维网，伟大的三个发明：

- URI:即统一资源标识符,作为互联网上资源的唯一身份
- HTML:即超文本标记语言,描述超文本文档
- HTTP:即超文本传输协议,用来传输超文本

### HTTP/0.9 原型

20 世纪 90 年代初期（网站都是纯文本格式）的 HTTP 被定义为 0.9 版，结构比较简单，为了便于服务器和客户端处理，它也采用了纯文本格式。最初设想的系统里的文档都是只读的，所以只允许用“GET”动作从服务器上获取 HTML 文档，并且在响应请求之后立即关闭连接，功能非常有限。

> GET 方法

![](../../img/网络/Xnip2020-06-03_17-53-02.jpg)

### HTTP/1.0

经过一系列的草案，HTTP/1.0 版本在 1996 年正式发布。它在多方面增强了 0.9 版，形式上已经和我们现在的 HTTP 差别不大 ，例如增加的有：

- HEAD POST 方法
- 状态码以及错误短语
- 引入了 HTTP 头部概念，让 HTTP 更加灵活
- 传输的格式不限于文本
- 需要使用 keep-alive 开启长连接

但 HTTP/1.0 并不是一个“标准”，只是记录已有实践和模式的一份参考文档，不具有实际的约束力，相当于一个“备忘录”。

### HTTP/1.1

在“浏览器大战”结束之后的 1999 年,HTTP/1.1 发布了 RFC 文档,编号为 2616,是一个“正式的标准”，而不是一份可有可无的“参考文档”。

增加的有：

- 新增 PUT DELETE 方法
- 增加了**缓存管理和控制**
- 明确了**连接管理**，默认长连接
- 允许**传输时对数据分块**（chunked），利于**大文件上传**

### HTTP/2.0

HTTP/1.1 发展到现在，虽然屹立不倒但存在着一个问题：“连接慢”，导致无法跟上迅猛发展的互联网。
Google 推出了新的协议：SPDY 并利用自家的生态系统，“挟用户以号令天下”，最终将 SPDY 推上了标准的宝座，互联网标准化组织以 SPDY 为基础开始制定新版本的 HTTP 协议，最终在 2015 年发布了 HTTP/2，RFC 编号 7540。

- 废弃 HTTP1.1 的管道，可以并发多个请求（多路复用）
- 专用算法对 HTTP 头部进行压缩，减少数据传输量
- 允许服务端向客户端发起网络推送数据（推动自家的 PWA~）
- 增强了安全性，要求加密通信（自家的 PWA 也必须是 HTTPS）

> 整体感觉就是为了自家的 PWA 而生，豪横的一盘棋。

### HTTP/3.0

这一次还是 Google，而且它要“革自己的命”。同样的套路，最终在 2018 年,互联网标准化组织 IETF 提议将“HTTP over QUIC”更名为“HTTP/3”并获得批准,HTTP/3 正式进入了标准化制订阶段,也许两三年后就会正式发布,到时候我们很可能会跳过 HTTP/2 直接进入 HTTP/3。

- 基于 UDP 的 QUIC 可靠传输协议，放弃了 TCP 协议
- QUIC 协议内置 TLS，不再需要 HTTPS

## 3. 说一下你对域名的理解？

### 域名的格式

域名是一个有层次的结构，是一串用“.”分隔的多个单词，最右边的被称为“顶级域名”，然后是“二级域名”，层级关系向左依次降低。

最左边的是主机名，通常用来表明主机的用途，比如“www”表示提供万维网服务、“mail”表示提供邮件服务。

> 看一下极客时间的域名“time.geekbang.org”，这里的“org”就是顶级域名，“geekbang”是二级域名，“time”则是主机名。使用这个域名，DNS 就会把它转换成相应的 IP 地址，你就可以访问极客时间的网站了。

### DNS 域名解析

就像 IP 地址必须转换成 MAC 地址才能访问主机一样，域名也必须要转换成 IP 地址，这个过程就是“域名解析”。

DNS 的核心系统是一个三层的树状、分布式服务，基本对应域名的结构：

- 根域名服务器（Root DNS Server）：管理顶级域名服务器，返回“com”“net”“cn”等顶级域名服务器的 IP 地址；
- 顶级域名服务器（Top-level DNS Server）：管理各自域名下的权威域名服务器，比如 com 顶级域名服务器可以返回 apple.com 域名服务器的 IP 地址；
- 权威域名服务器（Authoritative DNS Server）：管理自己域名下主机的 IP 地址，比如 apple.com 权威域名服务器可以返回 www.apple.com 的 IP 地址。

XXX: 图片

> 在这里根域名服务器是关键，它必须是众所周知的，否则下面的各级服务器就无从谈起了。目前全世界共有 13 组根域名服务器，又有数百台的镜像，保证一定能够被访问到。

例如，你要访问“www.apple.com”，就要进行下面的三次查询：

- 访问根域名服务器，它会告诉你“com”顶级域名服务器的地址；
- 访问“com”顶级域名服务器，它再告诉你“apple.com”域名服务器的地址；
- 最后访问“apple.com”域名服务器，就得到了“www.apple.com”的地址。

有了这个域名系统后，就可以按照从右至左的顺序，获得最终的 IP 地址。

在核心 DNS 系统之外，还有两种手段用来减轻域名解析的压力，并且能够更快地获取结果，基本思路就是“缓存”。

### DNS 缓存

#### “非权威域名服务器”

许多大公司、网络运行商都会建立自己的 DNS 服务器，作为用户 DNS 查询的代理，代替用户访问核心 DNS 系统。这些“野生”服务器被称为“非权威域名服务器”，可以缓存之前的查询结果，如果已经有了记录，就无需再向根服务器发起查询，直接返回对应的 IP 地址。

> 比较知名的 DNS 有 Google 的“8.8.8.8”，Microsoft 的“4.2.2.1”，还有 CloudFlare 的“1.1.1.1”等等。

#### 操作系统缓存

操作系统里也会对 DNS 解析结果做缓存，如果你之前访问过“www.apple.com”，那么下一次在浏览器里再输入这个网址的时候就不会再跑到 DNS 那里去问，直接在操作系统里就可以拿到 IP 地址。

另外，操作系统里还有一个特殊的“主机映射”文件，通常是一个可编辑的文本，在 Linux 里是“/etc/hosts”，如果操作系统在缓存里找不到 DNS 记录，就会找这个文件。

XXX: 图

## 4. 来描述一下 HTTP 报文结构

### 和 TCP 的关系

![TCP报文](../../img/网络/HTTP/TCP报文.jpg)

- 相同点：HTTP 协议也是与 TCP/UDP 类似,同样也需要在实际传输的数据前附加一些头数据
- 不同点：它是一个明文的协议,所以头数据都是 ASCII 码的文本（HTTP2 就不是了）

![HTTP报文](../../img/网络/HTTP/HTTP报文.jpg)

起始行（start line）：描述请求或响应的基本信息；
头部字段集合（header）：使用 key-value 形式更详细地说明报文；
消息正文（entity）：实际传输的数据，它不一定是纯文本，可以是图片、视频等二进制数据。

### 起始行

1. 请求行
   ![](../../img/网络/HTTP/请求行.jpg)

- 请求方法(是一个动词，如 GET/POST，表示对资源的操作)
- 请求目标 URI(通常是一个 URI，标记了请求方法要操作的资源)
- 协议版本号

2. 状态行
   ![](../../img/网络/HTTP/状态行.jpg)

> 在这里它不叫“响应行”,而是叫“状态行”(status line),意思是服务器响应的状态。

- 协议版本号
- 状态码(一个三位数，用代码的形式表示处理的结果，比如 200 是成功，500 是服务器错误)
- 短语(作为数字状态码补充，是更详细的解释文字，帮助人理解原因)

### 常用头字段

**1. 通用字段**

- Date(通常出现在响应头里,表示 HTTP 报文创建的时间,客户端可以使用这个时间再搭配其他字段决定缓存策略)
- Cache-Control
- Connection (连接管理)
- via（代理服务器）

**2. 请求字段（仅能出现在请求头里,进一步说明请求信息或者额外的附加条件）**

- Host（只能出现在请求头里,它同时也是唯一一个 HTTP/1.1 规范里要求必须出现的字段,也就是说,如果请求头里没有 Host,那这就是一个错误的报文。）

> Host 字段告诉服务器这个请求应该由哪个主机来处理,当一台计算机上托管了多个虚拟主机的时候,服务器端就需要用 Host 字段来选择,有点像是一个简单的“路由重定向”。

- User-Agent(它使用一个字符串来描述发起 HTTP 请求的客户端,服务器可以依据它来返回最合适此浏览器显示的页面。)

> 但由于历史的原因,User-Agent 非常混乱,每个浏览器都自称是“Mozilla”“Chrome”“Safari”,企图使用这个字段来互相“伪装”,导致 User-Agent 变得越来越长,最终变得毫无意义。

> 不过有的比较“诚实”的爬虫会在 User-Agent 里用“spider”标明自己是爬虫,所以可以利用这个字段实现简单的反爬虫策略。

- 内容协商系
  - Accept
  - ~Charset
  - ~Encoding
  - ~Language
- 协商缓存类 - if-Modified-since - if-None-Match
- range

**3. 响应字段（仅能出现在响应头里,补充说明响应报文的信息）**

- Server 字段

> Server 字段也不是必须要出现的,因为这会把服务器的一部分信息暴露给外界,如果这个版本恰好存在 bug,那么黑客就有可能利用 bug 攻陷服务器。所以,有的网站响应头里要么没有这个字段,要么就给出一个完全无关的描述信息。

- 重定向：locaction
- Etag
  > 弱 Etag 需要加上 W/

**4. 实体字段（它实际上属于通用字段,但专门描述 body 的额外信息）**

- 内容协商类 - Content-Length

> 它表示报文里 body 的长度,也就是请求头或响应头空行后面数据的长度。服务器看到这个字段,就知道了后续有多少数据,可以直接接收。如果没有这个字段,那么 body 就是不定长的, 需要使用 chunked 方式分段传输。

- 缓存时效类 - expires - Last-Modified

## 5. 说一下 HTTP 的内容协商？

HTTP 是应用层的协议，数据到达之后工作只能说是完成了一半，还必须要告诉上层应用（例如浏览器）这是什么数据才行，否则上层应用就会“不知所措”。

XXX:图

### MIME type 和 Encoding type 标识 body 内容

#### MIME type

但 HTTP “顺手牵羊”取了 MIME 其中的一部分，用来标记 body 的数据类型，这就是我们平常总能听到的“MIME type”。

> “多用途互联网邮件扩展”（Multipurpose Internet Mail Extensions），简称为 MIME,可以让电子邮件可以发送 ASCII 码以外的任意数据。

HTTP 里经常遇到的几个类别：

1. text：即文本格式的可读数据，我们最熟悉的应该就是 text/html 了，表示超文本文档，此外还有纯文本 text/plain、样式表 text/css 等。
2. image：即图像文件，有 image/gif、image/jpeg、image/png 等。
3. audio/video：音频和视频数据，例如 audio/mpeg、video/mp4 等。
4. application：数据格式不固定，可能是文本也可能是二进制，必须由上层应用程序来解释。常见的有 application/json，application/javascript、application/pdf 等，另外，如果实在是不知道数据是什么类型，像刚才说的“黑盒”，就会是 application/octet-stream，即不透明的二进制数据。

#### Encoding type

因为 HTTP 在传输时为了节约带宽，有时候还会压缩数据，为了不要让浏览器继续“猜”，还需要有一个“Encoding type”，告诉数据是用的什么编码格式，这样对方才能正确解压缩，还原出原始的数据。

1. gzip：GNU zip 压缩格式，也是互联网上最流行的压缩格式；
2. deflate：zlib（deflate）压缩格式，流行程度仅次于 gzip；
3. br：一种专门为 HTTP 优化的新压缩算法（Brotli）。

### 协商字段

#### 内容格式和压缩方式

Accept 请求头字段 和 Content 实体头字段,用于客户端和服务器进行“内容协商”。

XXX: 图

#### 语言类型使用的头字段

为了解决“国际化”的问题，HTTP 采用了与数据类型相似的解决方案，又引入了两个概念：语言类型与字符集。

所谓的“语言类型”就是人类使用的自然语言，例如英语、汉语、日语等。

所谓的“字符集”是用来处理计算机编码方式的。现在主要是 Unicode 和 UTF-8，它把世界上所有的语言都容纳在一种编码方案里，遵循 UTF-8 字符编码方式的 Unicode 字符集也成为了互联网上的标准字符集。

XXX: 图

## 6. 请求方法都有哪些？GET 和 POST 又有什么区别？

### 请求方法

Http/1.1 规定了八种方法，单词必须都是大写的形式。

1. GET:获取资源，可以理解为读取或者下载数据
2. HEAD:获取资源的元信息;
3. POST:向资源提交数据，相当于写入或上传数据;
4. PUT:类似 POST;
5. DELETE:删除资源;
6. CONNECT:建立特殊的连接隧道;
7. OPTIONS:列出可对资源实行的方法;
8. TRACE:追踪请求-响应的传输路径。

GET/HEAD
——从服务器获取资源
HEAD 和 GET 类似，也是从服务器获取资源，但是不会返回请求的实体数据，只有响应头（元信息），是 GET 的简易版，如果不需要资源的话，可以避免传输 body 数据的浪费。

POST/PUT
——向服务器提交数据，数据在 body 里；PUT 和 POST 作用类似，有微妙不同，通常 POST 标识新建，PUT 标识修改

DELETE
——删除资源，危险性大，很少用

CONNECT
——要求服务器为客户端和另一台远程服务器建立一条特殊的链接，这时 Web 服务器充当代理的角色

OPTIONS
——要求服务器列出可对资源实行的操作方法，在响应头 Allow 字段里返回。（主要用于跨域 CORS 处理）

TRACE
——用于对 HTTP 链路的测试或诊断，可以显示出请求 - 响应的传输路径。存在漏洞，会泄露网站的信息，所以通常也是禁止使用

#### 安全与幂等

安全：在 HTTP 协议里，所谓的安全，是指请求方法不会对服务器上的资源造成实质的修改，所有 只有 GET 和 HEAD 是安全的，因为是只读操作。

幂等：多次执行相同的操作，结果也都是相同的。

GET 和 HEAD 即是安全的也是幂等的，DELETE 可以多次删除同一个资源，效果都是“资源不存在”，所以也是幂等。

POST 是新增或提交数据，多次提交会创建多个资源，所以不是幂等的。

PUT 是替换或更新数据，多次更新一个资源，资源还是第一次更新的状态。所以是幂等的。

幂等：GET、HEAD、DELETE、PUT
非幂等：POST

### get 和 post 的区别

#### 语义

GET：获取资源，可以理解为读取或者下载数据

POST：向资源提交数据，相当于写入或上传数据

#### 幂等与缓存

**get**：“读取“一个资源。比如 Get 到一个 html 文件。反复读取不应该对访问的数据有副作用。比如”GET 一下，用户就下单了，返回订单已受理“，这是不可接受的。没有副作用被称为“幂等“（Idempotent)。因为 GET 因为是读取，就可以对 GET 请求的数据做缓存。这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如 nginx），或者做到 server 端（用 Etag，至少可以减少带宽消耗）

**post**：不幂等也就意味着不能随意多次执行。因此也就不能缓存。比如通过 POST 下一个单，服务器创建了新的订单，然后返回订单成功的界面。这个页面不能被缓存。

试想一下，如果 POST 请求被浏览器缓存了，那么下单请求就可以不向服务器发请求，而直接返回本地缓存的“下单成功界面”，却又没有真的在服务器下单。那是一件多么滑稽的事情。

> 这题是一个坑，谨慎回答多说无益（菜是原罪）

## 7. 常见状态码说一下？

具体有如下五类：

1××：提示信息，表示目前是协议处理的中间状态，还需要后续的操作；
2××：成功，报文已经收到并被正确处理；
3××：重定向，资源位置发生变动，需要客户端重新发送请求；
4××：客户端错误，请求报文有误，服务器无法处理；
5××：服务器错误，服务器在处理请求时内部发生了错误。

### 1xx

1×× 类状态码属于提示信息，是协议处理的中间状态，实际能够用到的时候很少。

> 我们偶尔能够见到的是“101 Switching Protocols”。它的意思是客户端使用 Upgrade 头字段，要求在 HTTP 协议的基础上改成其他的协议继续通信，比如 WebSocket。而如果服务器也同意变更协议，就会发送状态码 101，但这之后的数据传输就不会再使用 HTTP 了。

### 2xx

2×× 类状态码表示服务器收到并成功处理了客户端的请求，这也是客户端最愿意看到的状态码。

“200 OK”是最常见的成功状态码，表示一切正常，服务器如客户端所期望的那样返回了处理结果。非 HEAD 请求，通常在响应头后都会有 body 数据。

“204 No Content”是另一个很常见的成功状态码，它的含义与“200 OK”基本相同，但响应头后没有 body 数据。所以对于 Web 服务器来说，**正确地区分 200 和 204 是很必要的。**

“206 Partial Content”是 HTTP **分块下载**或**断点续传**的基础，在客户端发送“范围请求”、要求获取资源的部分数据时出现，它与 200 一样，也是服务器成功处理了请求，但 body 里的数据不是资源的全部，而是其中的一部分。

> 状态码 206 通常还会伴随着头字段“Content-Range”，表示响应报文里 body 数据的具体范围，供客户端确认，例如“Content-Range: bytes 0-99/2000”，意思是此次获取的是总计 2000 个字节的前 100 个字节。

### 3xx

3×× 类状态码表示客户端请求的资源发生了变动，客户端必须用新的 URI 重新发送请求获取资源，也就是通常所说的“重定向”.

“301 Moved Permanently”俗称“永久重定向”

“302 Found”俗称“临时重定向”，意思是请求的资源还在，但需要暂时用另一个 URI 来访问。

“304 Not Modified” 它用于 If-Modified-Since 等条件请求，表示资源未修改，用于**缓存控制**。它不具有通常的跳转含义，但可以理解成“重定向已到缓存的文件”（即“缓存重定向”）。

### 4xx

4×× 类状态码表示客户端**发送的请求报文**有误，**服务器无法处理**

“400 Bad Request”是一个通用的错误码，表示请求报文有错误，但具体是数据格式错误、缺少请求头还是 URI 超长它没有明确说，只是一个笼统的错误,后端开发时，别用，膈应人。

“403 Forbidden”实际上不是客户端的请求出错，而是表示服务器禁止访问资源（没权限）。

“404 Not Found”可能是我们最常看见也是最不愿意看到的一个状态码，它的原意是资源在本服务器上未找到，所以无法提供给客户端。

> 服务端开发时，给 404 时一定要语义明确，尽量不给 web 开发人员造成负担。

### 5xx

5×× 类状态码表示客户端请求报文正确，但服务器在处理时内部发生了错误，无法返回应有的响应数据，是服务器端的“错误码”。

“500 Internal Server Error”与 400 类似，也是一个通用的错误码，服务器究竟发生了什么错误我们是不知道的。

> 不过对于服务器来说这应该算是好事，通常不应该把服务器内部的详细信息，例如出错的函数调用栈告诉外界。

“501 Not Implemented”表示客户端请求的功能还不支持，这个错误码比 500 要“温和”一些，和“即将开业，敬请期待”的意思差不多

“502 Bad Gateway”通常是服务器作为网关或者代理时返回的错误码，表示服务器自身工作正常，访问后端服务器时发生了错误

“503 Service Unavailable”表示服务器当前很忙，暂时无法响应服务，我们上网时有时候遇到的“网络服务正忙，请稍后重试”的提示信息就是状态码 503。

## 8. HTTP 重定向有了解吗？

由服务器来发起的，浏览器使用者无法控制，相对地就可以称为“被动跳转”，这在 HTTP 协议里有个专门的名词叫做“重定向”（Redirection），这个过程是用户无感知的。

> 主动跳转说的是前端点击一个超链接这种

### 301、302 和 location

“Location”字段属于响应字段，必须出现在响应报文里。但只有配合 301/302 状态码才有意义，它标记了服务器要求重定向的 URI。

浏览器收到 301/302 报文，会检查响应头里有没有“Location”。如果有，就从字段值里提取出 URI，发出新的 HTTP 请求，相当于自动替我们点击了这个链接。

> 在“Location”里的 URI 既可以使用绝对 URI，也可以使用相对 URI。所谓“绝对 URI”，就是完整形式的 URI，包括 scheme、host:port、path 等。所谓“相对 URI”，就是省略了 scheme 和 host:port，只有 path 和 query 部分，是不完整的，但可以从请求上下文里计算得到。

### 重定向状态码

#### 301

301 俗称“永久重定向”（Moved Permanently），意思是原 URI 已经“永久”性地不存在了，**今后的所有请求都必须改用新的 URI**。

浏览器看到 301，就知道原来的 URI“过时”了，就会做适当的优化。比如历史记录、更新书签，下次可能就会直接用新的 URI 访问，省去了再次跳转的成本。搜索引擎的爬虫看到 301，也会更新索引库，不再使用老的 URI。

#### 302

302 俗称“临时重定向”（“Moved Temporarily”），意思是原 URI 处于“临时维护”状态，新的 URI 是起“顶包”作用的“临时工”。

浏览器或者爬虫看到 302，会认为原来的 URI 仍然有效，但暂时不可用，所以只会执行简单的跳转页面，不记录新的 URI，也不会有其他的多余动作，下次访问还是用原 URI。

### 重定向的应用场景

使用重定向跳转，核心是要理解“重定向”和“永久 / 临时”这两个关键词。

- “资源不可用”，需要用另一个新的 URI 来代替，例如域名变更、服务器变更、网站改版、系统维护，这些都会导致原 URI 指向的资源无法访问，为了避免出现 404，就需要用重定向跳转到新的 URI，继续为网民提供服务。

* “避免重复”，让多个网址都跳转到一个 URI，增加访问入口的同时还不会增加额外的工作量（有的网站都会申请多个名称类似的域名，然后把它们再重定向到主站上）。

- 如果域名、服务器、网站架构发生了大幅度的改变，原来的 URI 已经不能用了，必须用 301“永久重定向”，通知浏览器和搜索引擎更新到新地址，这也是搜索引擎优化（SEO）要考虑的因素之一。

* 原来的 URI 在将来的某个时间点还会恢复正常，常见的应用场景就是系统维护，把网站重定向到一个通知页面，告诉用户过一会儿再来访问。另一种用法就是“服务降级”，比如在双十一促销的时候，把订单查询、领积分等不重要的功能入口暂时关闭，保证核心服务能够正常运行。

## 9. 说一下你了解的缓存策略？

浏览器缓存机制有四个方面,获取资源时请求的优先级依次排列如下：

- memory cache
- service worker cache
- http cache
- push cache

> memory cache 是浏览器默认的缓存，形如 `from memory cache`，service worker cache 形如：`from ServiceWorker` 是 Web Worker 的缓存设置，push cache 是 HTTP2.0 的新特性

- [ ] HTTP2.0 新特性：push cache

### memory cache 和 Disk Cache

**Memory Cache** 也就是内存中的缓存，主要包含的是当前中页面中已经抓取到的资源,读取内存中的数据肯定比磁盘快,内存缓存虽然读取高效，但生命周期有限，受浏览器的 Tab 页面所影响。

其中一块重要的缓存资源是 preloader 相关指令（例如<link rel=“preload”>）下载的资源。这是浏览器提供的预加载器实现的资源下载，可以一边进行渲染流水线的进行，一边通过网络请求获取资源。

[通过 rel=“preload”进行内容预加载 - HTML（超文本标记语言） | MDN](https://developer.mozilla.org/zh-CN/docs/Web/HTML/Preloading_content)

Disk Cache 也就是存储在硬盘中的缓存，读取速度慢点，但是什么都能存储到磁盘中，**比之 Memory Cache 胜在容量和存储时效性上**。

在所有浏览器缓存中，Disk Cache 覆盖面基本是最大的。它会根据 HTTP Herder 中的字段判断哪些资源需要缓存，哪些资源可以不请求直接使用，哪些资源已经过期需要重新请求。

> HTTP 缓存的资源，大部分会放入 Disk Cache 中进行缓存，但和 memory cache 的边界除了 size 区分以外，我分不清。

### HTTP cache

缓存策略是基于**HTTP 协议**进行的，是浏览器端和服务端的通用缓存策略。

其中的字段以及所代表的含义可以参照分级策略、缓存流程图 和 cache-control 流程图进行复习并讲解。

#### 分级策略

![IMG_00C90CE32933-1](https://user-images.githubusercontent.com/53052047/81637523-2dcaa480-9449-11ea-8955-c74b9f9e1531.jpeg)

可以分为三层，根据命中顺序自底向上解释：

- 强缓存层，命中该层会直接通过浏览器级别缓存获取资源，不会发起网络请求。相关字段：expires/cache-control
- 协商缓存层，命中该层会判断缓存资源的时效性，发起网络请求。如果是 304 表示资源缓资源没变。相关字段：last-modified/etag
- 缓存失效(不存在缓存)层，命中该层会从服务器拉去最新的资源，发起网络请求。

> 缓存机制分为**强缓存**和**协商缓存**。优先级较高的是强缓存，在命中强缓存失败的情况下，才会走协商缓存。

#### 强缓存

强缓存是利用 http 头中的 Expires 和 Cache-Control 两个字段来控制的。当请求再次发出时，浏览器会根据其中的 expires 和 cache-control 判断目标资源是否“命中”强缓存，若命中且有效，则直接从缓存中获取资源，**不会再与服务端发生通信。**

**expires**

expires 是一个时间戳，接下来如果我们试图再次向服务器请求资源，浏览器就会先对比本地时间和 expires 的时间戳，如果本地时间小于 expires 设定的过期时间，那么就直接去缓存中取这个资源。

> 如果服务端和客户端的时间设置不同（或者我直接手动去把客户端的时间改掉）那么 expires 将无法达到我们的预期判断能力

考虑到 expires 的局限性，HTTP1.1 新增了 Cache-Control 字段来完成 expires 的任务。

**Cache-Control**

在 Cache-Control 中，我们通过 max-age 来控制资源的有效期。max-age 不是一个时间戳，而是一个[unix 时间戳](https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Date)。

> max-age 时间的计算起点是响应报文的创建时刻（即 Date 字段，也就是离开服务器的时刻），而不是客户端收到报文的时刻，也就是说包含了在链路传输过程中所有节点所停留的时间。

响应报文里还可以用其他的属性来更精确地指示浏览器应该如何使用缓存：

- no-store：不允许缓存，用于某些变化非常频繁的数据，例如秒杀页面；
- no-cache：它的字面含义容易与 no-store 搞混，实际的意思并不是不允许缓存，而是可以缓存，但在使用之前必须要去服务器验证是否过期，是否有最新的版本；
- must-revalidate：又是一个和 no-cache 相似的词，它的意思是如果缓存不过期就可以继续使用，但过期了如果还想用就必须去服务器验证。

#### 协商缓存

协商缓存依赖于服务端与浏览器之间的通信。

协商缓存机制下，浏览器需要向服务器去询问缓存的相关信息，进而判断是重新发起请求下载最新的资源还是从本地获取缓存的资源。
如果服务端提示缓存资源未改动（Not Modified），资源会被**重定向**到浏览器缓存，**这种情况下网络请求对应的状态码是 304**

**Last-Modified**

Last-Modified 是一个时间戳，如果我们启用了协商缓存，它会在首次请求时随着 Response Headers 返回.

随后我们每次请求时，会带上一个叫 If-Modified-Since 的时间戳字段，它的值正是上一次 response 返回给它的 last-modified 值.

存在的问题：

- 我们编辑了文件，但文件的内容没有改变（在服务器端）。服务端并不清楚我们是否真正改变了文件，它仍然通过最后编辑时间进行判断。因此这个资源在再次被请求时，会被当做新资源，进而引发一次完整的响应
- 当我们修改文件的速度过快时（比如花了 100ms 完成了改动），由于 If-Modified-Since 只能检查到以秒为最小计量单位的时间差，所以它是感知不到这个改动的

**Etag**

Etag 是由服务器为每个资源生成的唯一的 hash 值，这个 hash 是基于文件内容编码的，只要文件内容不同，它们对应的 Etag 就是不同的。

Etag 的生成过程需要服务器额外付出开销，会影响服务端的性能，这是它的弊端。

> 强 Etag 说的是只要有变动，不管最后结果是否相同，我都会改变。弱 Etag 说的是有变动但最终结果相同，那么原地踏步。

#### 缓存流程图

缓存判断整体流程如图所示，对应的分级策略和强制缓存、协商缓存以按照相应颜色进行标注。

![IMG_5546758932FD-1](https://user-images.githubusercontent.com/53052047/81637532-315e2b80-9449-11ea-9db5-0ab130c45e27.jpeg)

#### cache-control 流程图

该字段对于缓存是否生效有如下判断流程：

![IMG_80586FD28555-1](https://user-images.githubusercontent.com/53052047/81637545-34f1b280-9449-11ea-93a7-477ca675319e.jpeg)

> s-maxage 优先级高于 max-age，两者同时出现时，优先考虑 s-maxage。如果 s-maxage 未过期，则向代理服务器请求其缓存内容。注意：s-maxage 仅在代理服务器中生效，客户端中我们只考虑 max-age

> 详细的文章：[浅谈 Web 缓存 | AlloyTeam](http://www.alloyteam.com/2016/03/discussion-on-web-caching/)

## 10. HTTP 传输大文件有了解过吗？

### 数据压缩（Accept-Encoding）

如果压缩率能有 50%,也就是说 100K 的数据能够压缩成 50K 的大小,那么就相当于在带宽不变的情况下网速提升了一倍,加速的效果是非常明显的。

不过这个解决方法也有个缺点,gzip 等压缩算法通常只对**文本文件**有较好的压缩率,而图片、音频视频等多媒体数据本身就已经是高度压缩的,再用 gzip 处理也不会变小(甚至还有可能会增大一点)

### 分段传输（Transfer-Encoding: chunked）

“化整为零”的思路在 HTTP 协议里就是“chunked”分块传输编码,在响应报文里用头字段“Transfer-Encoding: chunked”来表示。

“Transfer-Encoding: chunked”和“Content-Length”这两个字段是互斥的，也就是说响应报文里这两个字段不能同时出现，一个响应报文的传输要么是长度已知，要么是长度未知（chunked），这一点你一定要记住。

XXX: 图

### 范围请求（Range,Accept-Ranges: bytes）

> 你在看当下正热播的某穿越剧，想跳过片头，直接看正片，或者有段剧情很无聊，想拖动进度条快进几分钟，这实际上是**想获取一个大文件其中的片段数据**，而**分块传输并没有这个能力**。

HTTP 协议为了满足这样的需求，提出了“范围请求”（range requests）的概念，允许客户端在请求头里使用专用字段来表示只获取文件的一部分，相当于是客户端的“化整为零”。

范围请求不是 Web 服务器必备的功能,可以实现也可以不实现,所以服务器必须在响应头里使用字段“Accept- Ranges: bytes”明确告知客户端:“我是支持范围请求的”

> 如果不支持的话该怎么办呢？服务器可以发送“Accept-Ranges: none”，或者干脆不发送“Accept-Ranges”字段，这样客户端就认为服务器没有实现范围请求功能，只能老老实实地收发整块文件了。

请求头 Range 是 HTTP 范围请求的专用字段，格式是“bytes=x-y”，其中的 x 和 y 是以字节为单位的数据范围。

> 要注意 x、y 表示的是“偏移量”，范围必须从 0 计数，例如前 10 个字节表示为“0-9”，第二个 10 字节表示为“10-19”，而“0-10”实际上是前 11 个字节。

服务器收到 Range 字段后，需要做四件事。

1. 检查文件请求范围是否超标，比如文件只有 100 个字节，但请求“200-300”，这就是范围越界了。服务器就会返回状态码 416，意思是“你的范围请求有误，我无法处理，请再检查一下”。
2. 如果范围正确，服务器就可以根据 Range 头计算偏移量，读取文件的片段了，返回状态码“206 Partial Content”，和 200 的意思差不多，但表示 body 只是原数据的一部分。
3. 服务器要添加一个响应头字段 Content-Range，告诉片段的实际偏移量和资源的总大小，格式是“bytes x-y/length”，与 Range 头区别在没有“=”，范围后多了总长度。例如，对于“0-10”的范围请求，值就是“bytes 0-10/100”。
4. 把片段用 TCP 发给客户端，一个范围请求就算是处理完了。

## 11. HTTP 连接管理 和 队头阻塞？

### 连接管理

![](../../img/网络/HTTP/长连接短连接.png)

#### 连接管理：短连接

HTTP 协议最初(0.9/1.0)是个非常简单的协议,通信过程也采用了简单的“请求 - 应答”方式。

它底层的数据传输基于 TCP/IP,每次发送请求前需要先与服务器建立连接,收到响应报文后会立即关闭连接。每次 HTTP 请求都需要 TCP 建立连接（1 个 RTT），以及关闭连接（2 个 RTT）共 3 个 RTT。

#### 连接管理：长连接

针对短连接暴露出的缺点,HTTP 协议就提出了“长连接”的通信方式,也叫“持久连接”(persistent connections)、“连接保活”(keep alive)、“连接复用”(connection reuse)。

**基于“成本均摊”的思路**，既然 TCP 的连接和关闭非常耗时间,那么就把这个时间成本由原来的一个“请求 - 应答”均摊到多个“请求 - 应答”上。
这样虽然不能改善 TCP 的连接效率,但基于“分母效应”,每个“请求 - 应答”的无效时间就会降低不少,整体传输效率也就提高了。

#### **长连接的缺点**

因为 TCP 连接长时间不关闭,服务器必须在内存里保存它的状态,这就**占用了服务器的资源**。

如果有大量的空闲长连接只连不发,就会很快耗尽服务器的资源,导致服务器无法为真正有需要的用户提供服务。

> 因此长连接也需要在恰当的时间关闭,不能永远保持与服务器的连接。

#### 关闭长连接

客户端关闭方式：可以在请求头里加上“Connection: close”字段,告诉服务器:“这次通信后就关闭连接”。

服务器端关闭方式：通常不会主动关闭连接,但也可以使用一些策略。拿 Nginx 来举例,它有两种方式:

1. 使用“keepalive_timeout”指令，设置长连接的超时时间，如果在一段时间内连接上没有任何数据收发就主动断开连接，避免空闲连接占用系统资源。
2. 使用“keepalive_requests”指令，设置长连接上可发送的最大请求次数。比如设置成 1000，那么当 Nginx 在这个连接上处理了 1000 个请求后，也会主动断开连接。

> 不过不管客户端是否显式要求长连接,如果服务器支持长连接,它总会在响应报文里放一个“Connection: keep- alive”字段，HTTP1.1 是默认支持长连接的

### 队头阻塞

“队头阻塞”与短连接和长连接无关,而是由 HTTP 基本的“请求 - 应答”模型所导致的。在通信管道中形成了一个先进先出的“串行”队列，队列里的请求没有轻重缓急的优先级,只有入队的先后顺序,排在最前面的请求被最优先处理。

![](../../img/网络/HTTP/队头阻塞.png)

#### 性能优化点

1. “并发连接”：同时对一个域名发起多个长连接, 用数量来解决质量的问题。但这种方式也存在缺陷。如果每个客户端都想自己快,建立很多个连接,用户数 × 并发数就会是个天文数字。服务器的资源根本就扛不住,或者被服务器认为是恶意攻击,反而会造成“拒绝服务”

> RFC2616 里明确限制每个客户端最多并发 2 个连接。不过实践证明这个数字实在是太小了,众多浏览器都“无视”标准,把这个上限提高到了 6~8。后来修订的 RFC7230 也就“顺水推舟”,取消了这个“2”的限制.

2. “域名分片”HTTP 协议和浏览器不是限制并发连接数量吗?好,那我就多开几个域名,比如 `shard1.test.com`、`shard2.test.com`,而这些域名都指向同一台服务器`www.test.com`,这样实际长连接的数量就又上去了.

#### 升级到 HTTP2

由于 HTTP2 采用二进制格式传输 header + body，通过流实现了多路复用，从根本上解决了 HTTP 层面的队头阻塞。

## 12. 描述一下 cookie？

### 背景

HTTP 是“无状态”的,这既是优点也是缺点。优点是服务器没有状态差异,可以很容易地组成集群,而缺点就是无法支持需要记录状态的事务操作。

随着 HTTP 应用领域的不断扩大,对“记忆能力”的需求也越来越强烈。比如网上论坛、电商购物,都需要“看客下菜”,只有记住用户的身份才能执行发帖子、下订单等一系列会话事务。

HTTP 的 Cookie 机制也是一样的道理,既然服务器记不住,那就在外部想办法记住。相当于是服务器给每个客户端都贴上一张小纸条,上面写了一些只有服务器才能理解的数据,需要的时候客户端把这些信息发给服务器,服务器看到 Cookie,就能够认出对方是谁

### 客户端和服务端配合

当用户通过浏览器第一次访问服务器的时候,服务器肯定是不知道他的身份的。所以,就要创建一个独特的身份标识数据,格式是“key=value”,然后放进 Set-Cookie 字段里, 随着响应报文一同发给浏览器

浏览器收到响应报文,看到里面有 Set-Cookie,知道这是服务器给的身份标识,于是就保存起来,下次再请求的时候就自动把这个值放进 Cookie 字段里发给服务器。

### Cookie 的属性

Cookie 就是服务器委托浏览器存储在客户端里的一些数据,而这些数据通常都会记录用户的关键识别信息。所以,就需要在“key=value”外再用一些手段来保护,防止外泄或窃取,这些手段就是 Cookie 的属性。

#### 生存周期

默认情况下 cookie 的有效期是浏览器关闭后失效，不过可以通过 Expires 和 Max-Age 两个属性来设置有效期。

#### 作用域

让浏览器仅发送给特定的服务器和 URI,避免被其他网站盗用。“Domain”和“Path”指定了 Cookie 所属的域名和路径,浏览器在发送 Cookie 前会从 URI 中提取出 host 和 path 部分,对比 Cookie 的属性。如果不满足条件,就不会在请求头里发送 Cookie。

#### 安全性

HttpOnly:会告诉浏览器,此 Cookie 只能通过浏览器 HTTP 协议传输,禁止其他方式访问,浏览器的 JS 引擎就会禁用 document.cookie 等一切相关的 API,脚本攻击也就无从谈起.

SameSite:防范“跨站请求伪造”(XSRF)攻击,设置成“SameSite=Strict”可以严格限定 Cookie 不能随着跳转链接跨站发送, 而“SameSite=Lax”则略宽松一点,允许 GET/HEAD 等安全方法,但禁止 POST 跨站发送。

Secure:表示这个 Cookie 仅能用 HTTPS 协议加密传输,明文的 HTTP 协议会禁止发送。但 Cookie 本身不是加密的,浏览器里还是以明文的形式存在。

#### Cookie 的应用

身份识别: 保存用户的登录信息,实现会话事务.

## 13. 说一下 HTTP2 和 HTTP3 ？

### HTTP2

#### 兼容 HTTP/1

由于 HTTPS 已经在安全方面做的非常好了，所以 HTTP/2 的唯一目标就是改进性能。但它不仅背负着众多的期待，同时还背负着 HTTP/1 庞大的历史包袱，所以协议的修改必须小心谨慎，**兼容性**是首要考虑的目标

因此 HTTP/2 把 HTTP 分解成了“语义”和“语法”两个部分，**“语义”层不做改动**，与 HTTP/1 完全一致（即 RFC7231）。比如请求方法、URI、状态码、头字段等概念都保留不变，这样就消除了再学习的成本，基于 HTTP 的上层应用也不需要做任何修改，可以无缝转换到 HTTP/2。

在“语义”保持稳定之后，HTTP/2 在“语法”层做了“天翻地覆”的改造，**完全变更了 HTTP 报文的传输格式**。

#### 压缩头部

由于报文 Header 一般会携带“User Agent”“Cookie”“Accept”“Server”等许多固定的头字段，多达几百字节甚至上千字节，但 Body 却经常只有几十字节（比如 GET 请求、204/301/304 响应）。更要命的是成千上万的请求响应报文里有**很多字段值都是重复的**，非常浪费，“长尾效应”导致大量带宽消耗在了这些冗余度极高的数据上。

所以，HTTP/2 把“头部压缩”作为性能改进的一个重点，优化的方式你也肯定能想到，还是“压缩”。

> 不过 HTTP/2 并没有使用传统的压缩算法，而是开发了专门的“HPACK”算法，在客户端和服务器两端建立“字典”，用索引号表示重复的字符串，还釆用哈夫曼编码来压缩整数和字符串，可以达到 50%~90% 的高压缩率。

#### 二进制格式

HTTP/2 在这方面没有“妥协”，决定改变延续了十多年的现状不再使用肉眼可见的 ASCII 码，而是向下层的 TCP/IP 协议“靠拢”，全面采用二进制格式。

它把 TCP 协议的部分特性挪到了应用层，把**原来的“Header+Body”的消息“打散”为数个小片的二进制“帧”（Frame）**，用“HEADERS”帧存放头数据、“DATA”帧存放实体数据。

HTTP/2 数据分帧后“Header+Body”的报文结构就完全消失了，协议看到的只是一个个的“碎片”。

![](../../img/网络/HTTP/流：Frame.png)

#### “流”:多路复用

消息的“碎片”到达目的地后应该怎么组装起来呢？HTTP/2 为此定义了一个“流”（Stream）的概念，它是**二进制帧的双向传输序列**，同一个消息往返的帧会分配一个**唯一的流 ID**。

因为“流”是虚拟的，实际上并不存在，所以 HTTP/2 就可以在一个 TCP 连接上用“流”同时发送多个“碎片化”的消息，这就是常说的 **“多路复用” ——多个往返通信都复用一个连接来处理**。
**
在 **“流”的层面** 上看，消息是一些**有序的“帧”序列**，而在 **“连接”的层面** 上看，消息却是 **乱序收发的“帧”。\*\* 多个请求 / 响应之间没有了顺序关系，不需要排队等待也就不会再出现“队头阻塞”（解决了 HTTP 的队头阻塞，而不是 TCP 的）问题，降低了延迟，大幅度提高了连接的利用率。

#### “流”:服务器推送

HTTP/2 还在一定程度上改变了传统的“请求 - 应答”工作模式，服务器不再是完全被动地响应请求，也可以新建“流”主动向客户端发送消息。比如，在浏览器刚请求 HTML 的时候就提前把可能会用到的 JS、CSS 文件发给客户端，减少等待的延迟，这被称为“服务器推送”

#### “流”

在 HTTP/2 连接上，虽然帧是乱序收发的，但只要它们都拥有相同的流 ID，就都属于一个流，而且在这个流里帧不是无序的，而是有着严格的先后顺序。

在概念上，一个 HTTP/2 的流就等同于一个 HTTP/1 里的“请求 - 应答”。在 HTTP/1 里一个“请求 - 响应”报文来回是一次 HTTP 通信，在 HTTP/2 里一个流也承载了相同的功能。

![](../../img/网络/HTTP/HTTP2%20流.png)

特点如下：

1. 流是**可并发**的，一个 HTTP/2 连接上可以同时发出多个流传输数据，也就是并发多请求，实现“多路复用”；
2. 客户端和服务器都可以创建流，双方互不干扰；
3. 流是双向的，一个流里面客户端和服务器都可以发送或接收数据帧，也就是一个“请求 - 应答”来回；
4. 流之间没有固定关系，彼此独立，但流内部的帧是有严格顺序的；
5. 流可以设置**优先级**，让服务器优先处理，比如先传 HTML/CSS，后传图片，优化用户体验；
6. 流 ID **不能重用，只能顺序递增**，客户端发起的 ID 是奇数，服务器端发起的 ID 是偶数；
7. 在流上发送“RST_STREAM”帧可以随时终止流，取消接收或发送；
8. 第 0 号流比较特殊，不能关闭，也不能发送数据帧，只能发送控制帧，用于流量控制。

#### “流”状态转换

![](../../img/网络/HTTP/流-状态转换.png)
最开始的时候流都是“空闲”（idle）状态，也就是“不存在”，可以理解成是待分配的“号段资源”。

当客户端发送 HEADERS 帧后，有了流 ID，流就进入了“打开”状态，两端都可以收发数据，然后客户端发送一个带“END_STREAM”标志位的帧，流就进入了“半关闭”状态。

这个“半关闭”状态很重要，意味着客户端的请求数据已经发送完了，需要接受响应数据，而服务器端也知道请求数据接收完毕，之后就要内部处理，再发送响应数据。响应数据发完了之后，也要带上“END_STREAM”标志位，表示数据发送完毕，这样流两端就都进入了“关闭”状态，流就结束了。

刚才也说过，流 ID 不能重用，所以流的生命周期就是 HTTP/1 里的一次完整的“请求 - 应答”，流关闭就是一次通信结束。

下一次再发请求就要开一个新流（而不是新连接），流 ID 不断增加，直到到达上限，发送“GOAWAY”帧开一个新的 TCP 连接，流 ID 就又可以重头计数。

你再看看这张图，是不是和 HTTP/1 里的标准“请求 - 应答”过程很像，只不过这是发生在虚拟的“流”上，而不是实际的 TCP 连接，又因为流可以并发，所以 HTTP/2 就可以实现无阻塞的多路复用。

#### 安全

由于 HTTPS 已经是大势所趋，而且主流的浏览器 Chrome、Firefox 等都公开宣布只支持加密的 HTTP/2，所以“事实上”的 HTTP/2 是加密的。也就是说，互联网上通常所能见到的 HTTP/2 都是使用“https”协议名，跑在 TLS 上面。

综上所述，HTTP/2 的协议栈如下所示：
![](../../img/网络/HTTP/http2%20协议栈.png)

### http3

贴一下 HTTP/3 的协议栈图，有个宏观的认识。

![](../../img/网络/HTTP/http3.png)

- HTTP/3 基于 QUIC 协议，完全解决了“队头阻塞”问题，弱网环境下的表现会优于 HTTP/2；
- QUIC 是一个新的传输层协议，建立在 UDP 之上，实现了可靠传输；QUIC 内含了 TLS1.3，只能加密通信，支持 0-RTT 快速建连；

## 14. HTTP 性能优化方向有哪些？

HTTP 最基本的就是“请求 - 应答”模型，在这个模型里有两个角色:客户端和服务器，还有中间的传输链路，考查性能就可以看这三个部分。

### 服务端

衡量服务器性能的主要指标有三个:吞吐量(requests per second)、并发数 (concurrency)和响应时间(time per request)。

#### 吞吐量

吞吐量就是我们常说的 RPS，每秒的请求次数，也有叫 TPS、QPS，它是服务器最基本的 性能指标，RPS 越高就说明服务器的性能越好。

#### 并发数

并发数反映的是服务器的负载能力，也就是服务器能够同时支持的客户端数量，当然也是越 多越好，能够服务更多的用户。

#### 响应时间

响应时间反映的是服务器的处理能力，也就是快慢程度，响应时间越短，单位时间内服务器 就能够给越多的用户提供服务，提高吞吐量和并发数。

### 客户端

客户端是信息的消费者，一切数据都要通过网络从服务器获取，所以它最基本的性能指标就 是“延迟”(latency)。

1. 第一个因素是不可逾越”的障碍——光速.
2. 第二个因素是带宽，它又包括接入互联网时的电缆、WiFi、4G 和运营商内部网络、 运营商之间网络的各种带宽，每一处都有可能成为数据传输的瓶颈，降低传输速度，增加延 迟。
3. 第三个因素是 DNS 查询，如果域名在本地没有缓存，就必须向 DNS 系统发起查询，引发 一连串的网络通信成本，而在获取 IP 地址之前客户端只能等待，无法访问网站。
4. 第四个因素是 TCP 握手，你应该对它比较熟悉了吧，必须要经过 SYN、SYN/ACK、ACK 三个包之后才能建立连接，它带来的延迟由光速和带宽共同决定。

### 中间链路

XXX:图

“第一公里”是指网站的出口，也就是服务器接入互联网的传输线路，它的带宽直接决定了 网站对外的服务能力，也就是吞吐量等指标。显然，优化性能应该在这“第一公里”加大投 入，尽量购买大带宽，接入更多的运营商网络。

“中间一公里”就是由许多小网络组成的实际的互联网，其实它远不止“一公里”，而是非 常非常庞大和复杂的网络，地理距离、网络互通都严重影响了传输速度。好在这里面有一个 HTTP 的“好帮手”——CDN，它可以帮助网站跨越“千山万水”，让这段距离看起来真 的就好像只有“一公里”。

“最后一公里”是用户访问互联网的入口，对于固网用户就是光纤、网线，对于移动用户就 是 WiFi、基站。以前它是客户端性能的主要瓶颈，延迟大带宽小，但随着近几年 4G 和高 速宽带的普及，“最后一公里”的情况已经好了很多，不再是制约性能的主要因素了。

## 15. 说说 HTTP 相关的代理有哪些？
